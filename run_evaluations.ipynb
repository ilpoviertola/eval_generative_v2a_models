{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate generative multimodal audio models\n",
    "\n",
    "Use this notebook to evaluate the generative multimodal audio models. This notebook uses following metrics:\n",
    "\n",
    "- Frechet Audio Distance (FAD)\n",
    "- Kulback-Leibler Divergence (KLD)\n",
    "- ImageBind score (IB)\n",
    "- Synchronisation Error (SE)\n",
    "\n",
    "## Setup\n",
    "User must have\n",
    "\n",
    "1. Generated audio samples\n",
    "1. GT audios for given videos that were used when generating the audio\n",
    "\n",
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from utils.utils import dataclass_from_dict\n",
    "from configs.evaluation_cfg import EvaluationCfg\n",
    "from metrics.evaluation_metrics import EvaluationMetrics\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation pipeline:\n",
      "sample_directory: /home/hdd/data/greatesthits/evaluation/23-12-20T00-45-15/generated_samples_23-12-20T09-17-40\n",
      "gt_directory: /home/hdd/data/greatesthits/evaluation/GT\n",
      "result_directory: /home/hdd/data/greatesthits/evaluation/23-12-20T00-45-15/generated_samples_23-12-20T09-17-40\n",
      "PipelineCfg(fad=FADCfg(model_name='vggish', sample_rate=16000, use_pca=False, use_activation=False, dtype='float32', embeddings_fn='vggish_embeddings.npy'), kld=KLDCfg(pretrained_length=10, batch_size=10, num_workers=10, duration=2.0))\n",
      "verbose: False\n"
     ]
    }
   ],
   "source": [
    "sample_dir = Path(\"/home/hdd/data/greatesthits/evaluation/23-12-20T00-45-15/generated_samples_23-12-20T09-17-40\")\n",
    "# init evaluation config with default KLD and FAD metrics\n",
    "evaluation_cfg = dataclass_from_dict(EvaluationCfg, {\"sample_directory\": sample_dir, \"pipeline\": {\"fad\": {}, \"kld\": {}}})\n",
    "assert type(evaluation_cfg) == EvaluationCfg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics\n",
    "Metrics class are initialised with the *EvaluationCfg* -class which defines the evaluation pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings found in sample directory (/home/hdd/data/greatesthits/evaluation/23-12-20T00-45-15/generated_samples_23-12-20T09-17-40/vggish_embeddings.npy)\n",
      "Embeddings found in gt directory (/home/hdd/data/greatesthits/evaluation/GT/vggish_embeddings.npy)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/ilpo/.cache/torch/hub/harritaylor_torchvggish_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAD: 2.864387990917186\n"
     ]
    }
   ],
   "source": [
    "metrics = EvaluationMetrics(evaluation_cfg)\n",
    "print(f\"FAD: {metrics.run_fad()}\")\n",
    "print(f\"KLD: {metrics.run_kld()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eval_gen_audio_models",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
